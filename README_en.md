[中文](README.md) | English

# LLM Stream Tuner

A framework for dynamic incremental open learning of large language models.

*Note: Both this English README and the Chinese README have been automatically generated by Qwen Code.*

## Description

LLM Stream Tuner is a framework designed for dynamic incremental open learning of large language models. It provides tools for continuously training and fine-tuning LLMs with streaming data, allowing models to adapt to new information over time without forgetting previously learned knowledge.

The framework supports various tasks including safety evaluation, adversarial attack generation, and incremental learning strategies. It's particularly focused on generating adversarial examples to improve model robustness and safety.

## Environment Setup

This project uses `uv` for dependency management. To set up the environment:

1. Install `uv` if you haven't already:
   ```bash
   pip3 install uv
   ```

2. Sync dependencies:
   ```bash
   uv sync
   ```

3. Activate the virtual environment:
   ```bash
   source .venv/bin/activate
   ```

4. Install pre-commit hooks:
   ```bash
   pre-commit install
   ```

For more information about `uv`, refer to the [documentation](https://docs.astral.sh/uv/) or [Chinese documentation](https://uv.doczh.com/).

## Usage

The main usage of this project is through the single task module:

```bash
uv run -m llm_stream_tuner.task.single --config-file-path ./configs/single.yaml
```

You can also pass additional arguments to override configuration values:

```bash
uv run -m llm_stream_tuner.task.single --config-file-path ./configs/single.yaml --model_cfgs.model_name_or_path Qwen/Qwen3-8B
```

### Configuration

The framework uses YAML configuration files to define experiment settings. The main configuration file is `configs/single.yaml`, which includes:

- Data loading configurations
- Model configurations
- Inference settings
- Safety judgment configurations
- Intent extraction settings
- Reminder generation settings
- Attack generation settings
- System prompt removal settings

## Design

The framework follows a modular design with the following key components:

1. **Task Module**: Defines different types of tasks (currently only SingleTask is implemented)
2. **Data Module**: Handles data loading and preprocessing
3. **Inference Module**: Manages model inference with various backends (vLLM, API-based)
4. **Pipeline Module**: Contains specialized components for different stages:
   - Safety Judger: Evaluates response safety
   - Intent Extractor: Extracts intent from prompts
   - Reminder Generator: Creates safety reminders
   - Attack Generator: Generates adversarial examples
   - System Prompt Remover: Removes system prompts
5. **Cache Manager**: Handles caching of inference results
6. **Utils Module**: Provides utility functions for logging, configuration, and file handling

The SingleTask workflow:
1. Load initial data and attack data
2. Perform initial attack on the model
3. Evaluate attack success rate
4. Extract intent from successful attacks
5. Generate safety reminders
6. Generate new adversarial examples
7. Iteratively refine attacks for a specified number of epochs
8. Save the resulting safe dataset

## Testing

The project includes unit tests in the `tests` directory. To run tests:

```bash
uv run pytest
```

Tests cover:
- Core functionality of each module
- Configuration loading and parsing
- Data processing pipelines
- Utility functions

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
